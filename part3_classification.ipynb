{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCEbPRAAjp0j"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import tensorflow_transform as tft\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "\n",
    "#Disable annoying \"warnings\" from tf that aren't relevant\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfwd8oA41sBJ",
    "outputId": "ee1b2519-5c16-4ae6-b79d-fdc657444eae"
   },
   "outputs": [],
   "source": [
    "# Load Data and Labels\n",
    "contentPath = \"GBT_data/\"\n",
    "\n",
    "inputlayer = 20\n",
    "#fileName = \"activation_20_layer_26\"\n",
    "#fileName = \"dense_11_layer_25\"\n",
    "#fileName = \"activation_19_layer_24\"\n",
    "fileName = \"batch_normalization_16_layer_20\"\n",
    "\n",
    "dataSuffix = \"_data.npy\"\n",
    "labelsSuffix = \"_labels.npy\"\n",
    "imgSuffix = \"img.npy\"\n",
    "batchSize = 99999\n",
    "\n",
    "train_x = np.load(contentPath + \"train/data/\" + fileName + dataSuffix)\n",
    "train_y = np.load(contentPath + \"train/labels/\" + fileName + labelsSuffix)\n",
    "train_y_img = np.load(contentPath + \"train/labels/\" + imgSuffix)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(batchSize).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_x = np.load(contentPath + \"validation/data/\" + fileName + dataSuffix)\n",
    "valid_y = np.load(contentPath + \"validation/labels/\" + fileName + labelsSuffix)\n",
    "valid_y_img = np.load(contentPath + \"validation/labels/\" + imgSuffix)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((valid_x, valid_y)).batch(batchSize).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_x = np.load(contentPath + \"test/data/\" + fileName + dataSuffix)\n",
    "test_y = np.load(contentPath + \"test/labels/\" + fileName + labelsSuffix)\n",
    "test_y_img = np.load(contentPath + \"test/labels/\" + imgSuffix)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(batchSize).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(valid_x.shape)\n",
    "print(test_x.shape)\n",
    "\n",
    "print(train_y_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLMtNxO65POB"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# depth_range = (10, 19, 1)\n",
    "# trees_range = (160, 341, 20)\n",
    "\n",
    "# depth_range = (12, 18, 5)\n",
    "# trees_range = (160, 400, 20)\n",
    "\n",
    "# depth_range = (12, 18, 5)\n",
    "# trees_range = (280, 431, 5)\n",
    "\n",
    "# depth_range = (12, 13, 5)\n",
    "# trees_range = (330, 385, 1)\n",
    "\n",
    "depth_range = (12, 13, 5)\n",
    "trees_range = (367, 368, 1)\n",
    "\n",
    "modelSaveDir = \"/home/prateek/training/models/classification\"\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def train_model(layer, max_depth, num_trees):\n",
    "  print(f'Training GBT with max_depth={max_depth} and num_trees={num_trees}:')\n",
    "  model = None\n",
    "  saveLoc = f\"{modelSaveDir}/{layer}_{max_depth}_{num_trees}_model\"\n",
    "  start_time = time.perf_counter()\n",
    "  if(os.path.isdir(saveLoc)):\n",
    "    model = tf.keras.saving.load_model(saveLoc)\n",
    "    end_time = time.perf_counter()\n",
    "    print(f' - Loaded from file in {int(end_time-start_time)}s!')\n",
    "  else:\n",
    "    model = tfdf.keras.GradientBoostedTreesModel(max_depth=max_depth, num_trees=num_trees, early_stopping=\"NONE\", verbose=0)\n",
    "    model.fit(train_dataset)\n",
    "    model.compile(metrics=[\"accuracy\"])\n",
    "    model.save(saveLoc)\n",
    "    end_time = time.perf_counter()\n",
    "    print(f' - Took {int(end_time-start_time)}s ({int((end_time-start_time)/60*100)/100}m)!')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3y0n8rTsEOFL",
    "outputId": "582793ea-81bd-4348-bdd3-1c13c32ed884",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train Gradient Boosted Trees Model\n",
    "models = [] #[[max_depth, num_trees, model], ...]\n",
    "for max_depth in range(*depth_range):\n",
    "  for num_trees in range(*trees_range):\n",
    "    models.append([max_depth, num_trees, train_model(inputlayer, max_depth, num_trees)])\n",
    "\n",
    "print(f'{len(models)} models trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKBWt2aCXP5Z",
    "outputId": "a96fc8a0-4948-4694-c013-d1e9b4b95f47",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get accuracies of the trained models\n",
    "accuracies = [] #[[max_depth, num_trees, accuracy, model], ...]\n",
    "accuracies_train = [] #[[max_depth, num_trees, accuracy, model], ...]\n",
    "\n",
    "def get_accuracies(ds, lst):\n",
    "    for model_list in models:\n",
    "      model = model_list[2]\n",
    "      evaluation = model.evaluate(ds, return_dict=True, verbose=0)\n",
    "      lst.append((model_list[0], model_list[1], evaluation[\"accuracy\"], model))\n",
    "\n",
    "print(\"Getting validation accuracies...\")\n",
    "get_accuracies(valid_dataset, accuracies)\n",
    "print(\"Getting training accuracies...\")\n",
    "get_accuracies(train_dataset, accuracies_train)\n",
    "\n",
    "# Sort by accuracy\n",
    "#accuracies.sort(key=lambda x: -x[2])\n",
    "\n",
    "for (d, n, a, _) in accuracies_train:\n",
    "  print(f'd={d}, n={n}, a={a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "7UhxEOCzrIPd",
    "outputId": "740296c8-5e3c-474e-d781-dc7e5fc4bcac"
   },
   "outputs": [],
   "source": [
    "# Plot accuracy heatmap\n",
    "depths = []\n",
    "trees = []\n",
    "values = []\n",
    "\n",
    "for n in range(*depth_range):\n",
    "  depths.append(n)\n",
    "\n",
    "for n in range(*trees_range):\n",
    "  trees.append(n)\n",
    "\n",
    "for depth in range(*depth_range):\n",
    "  row = []\n",
    "  for n_trees in range(*trees_range):\n",
    "    accur = 0\n",
    "    for tpl in accuracies_train:\n",
    "      if(tpl[0] == depth and tpl[1] == n_trees):\n",
    "        accur = tpl[2]\n",
    "        break\n",
    "    row.append(accur)\n",
    "  values.append(row)\n",
    "\n",
    "values = np.array(values)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(values)\n",
    "\n",
    "ax.set_yticks(np.arange(len(depths)), labels=depths)\n",
    "ax.set_xticks(np.arange(len(trees)), labels=trees)\n",
    "\n",
    "for i in range(len(depths)):\n",
    "    for j in range(len(trees)):\n",
    "        val = int(values[i, j]*10000)/10000\n",
    "        color = \"black\"\n",
    "        #if(val >= 0.613):\n",
    "        #  color = \"r\"\n",
    "        text = ax.text(j, i, val,\n",
    "                       ha=\"center\", va=\"center\", color=color, size=8)\n",
    "        \n",
    "fig.set_figwidth(15)\n",
    "fig.colorbar(im, ax=ax)\n",
    "\n",
    "ax.set_title(\"Accuracy for Training Set\\n(Higher is Better)\")\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"Maximum Depth of Trees\")\n",
    "\n",
    "#fig.set_size_inches(15,10)\n",
    "#fig.set_size_inches(15,3)\n",
    "fig.set_size_inches(23,3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "id": "D3KU8RcDSc4y",
    "outputId": "f85928bd-33d2-46c3-a9f6-58c271414f2f"
   },
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "# (true, predicted)\n",
    "CATEGORIES = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
    "\n",
    "matrix = np.zeros((7, 7))\n",
    "\n",
    "#bestModel = accuracies[0][3]\n",
    "#prediction = bestModel.predict(test_dataset)\n",
    "\n",
    "for n in range(prediction.shape[0]):\n",
    "  #predicted = np.argmax(prediction[n])\n",
    "  predicted = np.argmax(test_x[n])\n",
    "  truth = test_y[n]\n",
    "  matrix[truth, predicted] += 1\n",
    "\n",
    "#Normalize\n",
    "row_sums = matrix.sum(axis=1)\n",
    "matrix = matrix / row_sums[:, np.newaxis]\n",
    "\n",
    "#Render Image\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(matrix)\n",
    "\n",
    "ax.set_yticks(np.arange(len(CATEGORIES)), labels=CATEGORIES)\n",
    "ax.set_xticks(np.arange(len(CATEGORIES)), labels=CATEGORIES)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        val = int(matrix[i, j]*10000)/10000\n",
    "        color = \"r\"\n",
    "        text = ax.text(j, i, val,\n",
    "                       ha=\"center\", va=\"center\", color=color, size=7)\n",
    "\n",
    "fig.set_figwidth(15)\n",
    "fig.colorbar(im, ax=ax)\n",
    "\n",
    "ax.set_title(\"Confusion Matrix for Test Dataset\\n(CNN)\")\n",
    "\n",
    "plt.xlabel(\"Truth\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph for when max_depth is fixed at 12\n",
    "\n",
    "resultsValidation_N = [i[1] for i in accuracies if i[0] == 12]\n",
    "resultsValidation_Error = [1 - i[2] for i in accuracies if i[0] == 12]\n",
    "\n",
    "resultsTraining_N = [i[1] for i in accuracies_train if i[0] == 12]\n",
    "resultsTraining_Error = [1 - i[2] for i in accuracies_train if i[0] == 12]\n",
    "\n",
    "plt.plot(resultsValidation_N, resultsValidation_Error, label='Validation')\n",
    "plt.plot(resultsTraining_N, resultsTraining_Error, label='Training', color='#ff7f0e')\n",
    "\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Classification Error for GBTs with max depth of 12\\n(Lower is Better)\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
